{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8c5924-7950-48cd-b6c0-68f427113257",
   "metadata": {},
   "source": [
    "### Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad14a4-63c6-4efe-8e4b-3fc7d9b1ff7d",
   "metadata": {},
   "source": [
    "Ridge Regression(L2), used for preventing overfitting , also eliminate muilti collinearlity.\n",
    "L2 adds a penalty term to the cost function to shrink the coefficients towards zero, whereas OLS regression does not include any regularization techniques. The purpose of the penalty term is to reduce the impact of multicollinearity in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f039ea-5d21-4ecb-8ac2-92995d156224",
   "metadata": {},
   "source": [
    "#### Q2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603eda80-da1b-44cc-a01e-0ea1dec06d1a",
   "metadata": {},
   "source": [
    "The number of predictor variables in a given set exceeds the number of observations.\n",
    "\n",
    "The dataset has multicollinearity (correlations between predictor variables).\n",
    "\n",
    "Ridge Regression shrinks the value of coefficients but doesn’t reach zero, which suggests no feature selection feature.\n",
    "\n",
    "Ridge Regression is a regularization method and uses l2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c636a-9cfd-415d-859f-084b26bee938",
   "metadata": {},
   "source": [
    "### Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a3d5d-e285-48e8-a8e3-128c6bc8709f",
   "metadata": {},
   "source": [
    "The value of the penalty term lambda (λ) in Ridge Regression is used to control the amount of shrinkage applied to the coefficients. A larger value of lambda results in greater shrinkage and a simpler model, while a smaller value of lambda results in less shrinkage and a more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e2f40-dd71-4ce1-8908-294c93dc4878",
   "metadata": {},
   "source": [
    "### Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74626f31-4f63-4d25-8531-a6448ef7f3ea",
   "metadata": {},
   "source": [
    "Yes , Ridge Regression shrinks the value of coefficients but doesn’t reach zero, which suggests no feature selection feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482024b-18c1-4fc4-bbc6-0d4eb38c4758",
   "metadata": {},
   "source": [
    "### Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42742526-ec1c-4e85-bbd6-ca9328acfa06",
   "metadata": {},
   "source": [
    "Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity. This method performs L2 regularization. When the issue of multicollinearity occurs, least-squares are unbiased, and variances are large, this results in predicted values being far away from the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28e039-999c-4761-b281-af6bbe45aabc",
   "metadata": {},
   "source": [
    "### Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97006874-7a7f-4565-9c8b-7f05ba9b61ac",
   "metadata": {},
   "source": [
    "Ridge regression can indeed handle both categorical and continuous independent variables. We need to encode categorical variables appropriately and choose an appropriate value for λ based on cross-validation.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa392382-1e06-4007-954a-db5f8fa0eef1",
   "metadata": {},
   "source": [
    "### Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb86eda-e256-410b-bb92-d73017480297",
   "metadata": {},
   "source": [
    "When predictor variables are highly correlated (multicollinearity), coefficient estimates become unreliable and have high variance.\n",
    "\n",
    "Ridge regression introduces a shrinkage penalty term to the OLS loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e1e5d-28b5-4d5e-9c63-6bbc64f3c782",
   "metadata": {},
   "source": [
    "### Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b66767-4d0e-4357-b2b1-dfc14240247b",
   "metadata": {},
   "source": [
    "Ridge Regression can be applied to time-series data, it's important to consider the characteristics of time-series analysis and make appropriate adjustments to the model and data preprocessing steps. Additionally, depending on the specific characteristics of your time series, other time-series models like autoregressive integrated moving average (ARIMA) or seasonal decomposition of time series (STL) may also be worth exploring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61ff0a-023e-48aa-b49d-a1093e4420ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
